\section{Qualitätsmessung der Kompression}
Um die Datenmenge der Feldlinien zu verringern werden verlustbehaftete Kompressionsverfahren angewendet. Trotz des Dateverlustes sollen die dekomprimierten Linien möglichst ihren Originalen ähneln. Kleine Abweichungen werden von den Sonnenforschern toleriert. Ihnen ist wichtig, dass vorallem die Form der Kurve möglichst erhalten bleibt. Grosse Abweichungen, die selten eintreten, können aber das Aussehen einer Kurve grundlegend verändern.\\[\baselineskip]
Zusammen mit den Sonnenforschern wurden zwei Fehlermasse bestimmt: Der absolute maximale Fehler und die Standardabweichung von der komprimierten Linie zum Original. 
formel der Standardabweichung, grosse Abweichungen werden stärker gewichtet.\\
Der absolute maximale Fehler wird noch als Absicherung gemessen. In den meisten Fällen wird die Kompression mit der tieferen Standardabweichung auch den kleineren maximalen Fehler haben. Da aber die Messung über ein paar hunderttausend Punkte durchgeführt wird, ist das Gegenteil denkbar. Eine gute Kompression muss es einen minimalen absoluten Fehler haben und eine minimale Standardabweichung bei minimalem Platzbedarf.\\[\baselineskip]
Bei einer verlustbehafteten Kompression ist ein Kompromiss zwischen Platzbedarf und Genauigkeit zu finden. Eine feste Fehlergrenze, welche die Kompression nicht überschreiten darf, wäre für die Entwicklung hilfreich. So eine Grenze ist aber nur intuitiv festzulegen.

Um Verfahren trotzdem zu Testen und zu vergleichen werden kompressionen mehrfach in verschiedenen qualitätsstufen getestet und jeweils den Fehler und die resultierende Dateigrösse verglichen.

Bild eines Beispielgraphen

\subsection{Auswahl und Erhebung der Testdaten}
Die Testdaten sollen zu einem alle Randfälle abdecken, als auch durchschnittliche Fälle enthalten. Aus diesem Grund wurden insgesamt zehn Datensätze ausgewählt. 
Insgesamt wurden 10 Datensätze ausgewählt. Nach grossen Solar Flares gesucht vier Datensätze mit grossen Flares, zwei mit sehr wenig Sonnenaktivität und vier zufällig.
Die feldlinien werden aber nur alle sechs Stunden berechnet und ein Flare ist ein kurzes ereignis. Es wurden die Datensätze vor dem Ereignis ausgewählt.

wie im Abschnitt \ref{konzept:ist-komprimierung} beschrieben, führt der IDL-Code schon eine Quantisierung durch. deshalb wurde der IDL Code angepasst, quantisierung entfernt und dateien mit float genauigkeit genommen.  

Problem mit letzter linie

\subsection{Messung des Fehlers}
Expected

Actual

Acutal <= expected

Ich weiss, welches der Originalpunkt ist.
